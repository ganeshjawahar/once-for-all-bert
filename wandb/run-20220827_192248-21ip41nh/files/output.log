
pre-initialized with BERT weights
/data/home/ganayu/miniconda/envs/basic/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Traceback (most recent call last):
  File "train_mlm.py", line 2257, in <module>
    main()
  File "train_mlm.py", line 1221, in main
    model = custom_bert.BertForMaskedLM.from_pretrained(
  File "/data/home/ganayu/miniconda/envs/basic/lib/python3.8/site-packages/transformers/modeling_utils.py", line 1385, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_bert.py", line 2566, in __init__
    self.bert = BertModel(config, add_pooling_layer=False)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_bert.py", line 2055, in __init__
    self.encoder = BertEncoder(config)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_bert.py", line 1573, in __init__
    [layer_function(config) for _ in range(config.sample_num_hidden_layers)] # changed to sample_num_hidden_layers (finetuning bug)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_bert.py", line 1573, in <listcomp>
    [layer_function(config) for _ in range(config.sample_num_hidden_layers)] # changed to sample_num_hidden_layers (finetuning bug)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_bert.py", line 1387, in __init__
    self.output = BertOutput(config)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_bert.py", line 1274, in __init__
    self.dense = CustomLinear(config.intermediate_size, config.hidden_size)
  File "/fsx/ganayu/code/SuperShaper/custom_layers/custom_linear.py", line 16, in __init__
    super().__init__(super_in_dim, super_out_dim, bias=bias)
  File "/data/home/ganayu/miniconda/envs/basic/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 90, in __init__
    self.reset_parameters()
  File "/data/home/ganayu/miniconda/envs/basic/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 96, in reset_parameters
    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
  File "/data/home/ganayu/miniconda/envs/basic/lib/python3.8/site-packages/torch/nn/init.py", line 410, in kaiming_uniform_
    return tensor.uniform_(-bound, bound)
KeyboardInterrupt