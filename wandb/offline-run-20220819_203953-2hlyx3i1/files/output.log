Subnet info: Model-Size=66690408, Val-PPL=6.315006387005788
Subnet info: Gene=[360, 240, 240, 360, 360, 360, 540, 360, 480, 540, 540, 600]
Subnet info: Search_space_id=
Subnet info: elastic_keys= ['sample_hidden_size']
Subnet info: gene_choices= [[120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768], [120, 240, 360, 480, 540, 600, 768]]
Subnet info: gene_names= ['sample_hidden_size_0', 'sample_hidden_size_1', 'sample_hidden_size_2', 'sample_hidden_size_3', 'sample_hidden_size_4', 'sample_hidden_size_5', 'sample_hidden_size_6', 'sample_hidden_size_7', 'sample_hidden_size_8', 'sample_hidden_size_9', 'sample_hidden_size_10', 'sample_hidden_size_11']
Subnet info: elastickey2ranges= {'sample_hidden_size': [0, 12]}
Number of parameters in custom config is 67 Million
=====================================================================================
Layer (type:depth-idx)                                       Param #
=====================================================================================
BertForSequenceClassification                                --
├─BertModel: 1-1                                             --
│    └─BertEmbeddings: 2-1                                   --
│    │    └─CustomEmbedding: 3-1                             23,440,896
│    │    └─CustomEmbedding: 3-2                             393,216
│    │    └─CustomEmbedding: 3-3                             1,536
│    │    └─CustomLayerNorm: 3-4                             1,536
│    │    └─Dropout: 3-5                                     --
│    └─BertEncoder: 2-2                                      --
│    │    └─ModuleList: 3-6                                  --
│    │    │    └─BertLayer: 4-1                              8,269,056
│    │    │    └─BertLayer: 4-2                              8,269,056
│    │    │    └─BertLayer: 4-3                              8,269,056
│    │    │    └─BertLayer: 4-4                              8,269,056
│    │    │    └─BertLayer: 4-5                              8,269,056
│    │    │    └─BertLayer: 4-6                              8,269,056
│    │    │    └─BertLayer: 4-7                              8,269,056
│    │    │    └─BertLayer: 4-8                              8,269,056
│    │    │    └─BertLayer: 4-9                              8,269,056
│    │    │    └─BertLayer: 4-10                             8,269,056
│    │    │    └─BertLayer: 4-11                             8,269,056
│    │    │    └─BertLayer: 4-12                             8,269,056
│    └─BertPooler: 2-3                                       --
│    │    └─CustomLinear: 3-7                                590,592
│    │    └─Tanh: 3-8                                        --
├─Dropout: 1-2                                               --
├─CustomLinear: 1-3                                          1,538
=====================================================================================
Total params: 123,657,986
Trainable params: 123,657,986
Non-trainable params: 0
=====================================================================================
setting teachers requires_grad to False
setting the subnet...
BertConfig {
  "_name_or_path": "/fsx/ganayu/experiments/supershaper/aug13_v1_acadbertdata_supernet_retrain_subnet_125Ksteps/supernet_continue/best_model",
  "additional_random_softmaxing": false,
  "alpha_divergence": 0,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bottleneck_rank": 50,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "hypernet_hidden_size": 64,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_drop_prob": 0.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "max_seq_length": 128,
  "mixing": "bert-bottleneck",
  "model_type": "bert",
  "normalization_type": "layer_norm",
  "num_attention_heads": 12,
  "num_feedforward_networks": 1,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "random_layer_selection_probability": 0.1,
  "rewire": 0,
  "sample_hidden_size": [
    360,
    240,
    240,
    360,
    360,
    360,
    540,
    360,
    480,
    540,
    540,
    600
  ],
  "sample_intermediate_size": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  "sample_num_attention_heads": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  "sample_num_hidden_layers": 12,
  "search_space_id": null,
  "transformers_version": "4.11.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "use_hypernet_w_low_rank": 0,
  "vocab_size": 30522
}
1: None None
(tensor([[[-1.2342e-03, -0.0000e+00,  1.2822e-02,  ...,  0.0000e+00,
           4.8333e-03,  1.0474e-02],
         [-7.6929e-01, -8.6962e-01, -0.0000e+00,  ..., -1.3418e-01,
          -2.8161e-01,  1.6900e-01],
         [-7.7937e-01, -7.6471e-01,  1.7525e-01,  ..., -6.8033e-01,
          -1.5021e-01,  5.4873e-01],
         ...,
         [ 1.1328e-01, -1.7176e-01, -9.1277e-02,  ..., -3.6336e-01,
          -1.2116e-01, -3.7284e-03],
         [ 2.2663e-01, -2.9655e-02, -1.4285e-01,  ..., -0.0000e+00,
          -2.9477e-01,  7.4418e-02],
         [ 0.0000e+00,  8.4267e-02, -1.2642e-01,  ..., -1.1556e-01,
          -3.8121e-01, -9.0117e-03]],
        [[-1.2342e-03, -5.5803e-03,  1.2822e-02,  ...,  2.9898e-03,
           4.8333e-03,  1.0474e-02],
         [ 1.3805e-02, -1.3645e+00, -1.5385e-01,  ..., -0.0000e+00,
           4.5547e-01, -1.2543e-01],
         [-1.3436e-01, -1.8587e-02, -4.1913e-01,  ...,  7.4479e-01,
           5.5234e-01,  2.3113e-01],
         ...,
         [ 1.1328e-01, -1.7176e-01, -9.1277e-02,  ..., -3.6336e-01,
          -1.2116e-01, -3.7284e-03],
         [ 2.2663e-01, -2.9655e-02, -0.0000e+00,  ..., -3.1879e-01,
          -2.9477e-01,  7.4418e-02],
         [ 5.1339e-01,  8.4267e-02, -1.2642e-01,  ..., -1.1556e-01,
          -0.0000e+00, -9.0117e-03]],
        [[-1.2342e-03, -5.5803e-03,  1.2822e-02,  ...,  2.9898e-03,
           4.8333e-03,  0.0000e+00],
         [-1.2502e+00, -1.0223e-01, -4.8538e-01,  ...,  1.0109e+00,
          -1.7188e-01,  2.6256e-01],
         [-4.0405e-01, -0.0000e+00,  4.4150e-01,  ..., -3.4051e-01,
           7.1410e-01, -4.4223e-02],
         ...,
         [ 1.1328e-01, -1.7176e-01, -0.0000e+00,  ..., -3.6336e-01,
          -0.0000e+00, -3.7284e-03],
         [ 2.2663e-01, -2.9655e-02, -1.4285e-01,  ..., -3.1879e-01,
          -2.9477e-01,  7.4418e-02],
         [ 5.1339e-01,  8.4267e-02, -1.2642e-01,  ..., -1.1556e-01,
          -3.8121e-01, -9.0117e-03]],
        ...,
        [[-1.2342e-03, -5.5803e-03,  1.2822e-02,  ...,  2.9898e-03,
           4.8333e-03,  1.0474e-02],
         [ 1.5744e-01, -6.5438e-01, -6.1980e-01,  ...,  9.1660e-01,
          -7.1492e-01,  4.0518e-01],
         [-2.1810e-01, -7.5605e-01,  1.3126e-01,  ...,  5.0469e-02,
           5.5026e-01, -8.9770e-01],
         ...,
         [ 1.1328e-01, -1.7176e-01, -9.1277e-02,  ..., -3.6336e-01,
          -1.2116e-01, -0.0000e+00],
         [ 2.2663e-01, -2.9655e-02, -1.4285e-01,  ..., -3.1879e-01,
          -2.9477e-01,  7.4418e-02],
         [ 5.1339e-01,  8.4267e-02, -1.2642e-01,  ..., -1.1556e-01,
          -3.8121e-01, -9.0117e-03]],
        [[-1.2342e-03, -5.5803e-03,  1.2822e-02,  ...,  2.9898e-03,
           4.8333e-03,  1.0474e-02],
         [ 3.5487e-02, -1.7238e-01, -3.8395e-01,  ..., -5.3954e-01,
           8.1700e-01,  1.3703e-02],
         [ 4.6067e-01, -1.2395e-01,  9.7937e-02,  ..., -0.0000e+00,
          -3.0292e-01,  1.4921e-01],
         ...,
         [ 6.1640e-01, -6.0051e-01, -5.4402e-01,  ..., -1.5022e-01,
           2.1080e-01, -3.9967e-01],
         [ 8.2630e-02,  1.9226e-01,  6.9067e-02,  ..., -1.8408e-01,
          -4.6816e-02,  8.5063e-02],
         [ 7.2501e-02,  1.1817e-01,  0.0000e+00,  ..., -2.1675e-02,
           1.7325e-01,  7.7635e-02]],
        [[-1.2342e-03, -5.5803e-03,  1.2822e-02,  ...,  2.9898e-03,
           4.8333e-03,  0.0000e+00],
         [-4.3991e-01, -9.2694e-01, -9.6188e-01,  ...,  6.3918e-01,
          -4.0430e-01, -0.0000e+00],
         [-4.3331e-01, -4.9182e-01,  5.7365e-02,  ...,  3.8973e-01,
           4.2072e-01, -7.5823e-02],
         ...,
         [-7.8911e-02, -1.7789e-01,  3.7125e-01,  ...,  2.4861e-01,
           8.2725e-01, -3.7924e-01],
         [ 8.2630e-02,  1.9226e-01,  6.9067e-02,  ..., -1.8408e-01,
          -4.6816e-02,  8.5063e-02],
         [ 7.2501e-02,  1.1817e-01,  1.6186e-01,  ..., -2.1675e-02,
           1.7325e-01,  7.7635e-02]]], device='cuda:0'), tensor([[[-3.5674e-03,  2.6302e-03, -4.1933e-02,  ..., -1.2797e-02,
          -2.6998e-02,  1.5342e-02],
         [-9.9572e-01, -6.0858e-01,  3.1086e-01,  ..., -1.9661e-01,
          -3.8346e-01,  1.5169e-01],
         [-6.2878e-01, -5.2334e-01,  2.3522e-01,  ..., -8.5930e-01,
          -1.3242e-01,  3.2680e-01],
         ...,
         [ 3.6324e-01, -2.2968e-01,  1.9312e-01,  ..., -2.3069e-01,
           4.3893e-01, -8.9602e-02],
         [ 4.6198e-01, -1.4858e-01,  3.9812e-02,  ...,  1.7487e-01,
           3.6502e-01, -6.5999e-02],
         [ 2.3845e-01, -4.8167e-02,  1.0071e-01,  ...,  4.8025e-02,
           2.1858e-01, -1.1278e-01]],
        [[-1.2298e-02,  1.2561e-03, -4.7371e-02,  ..., -1.5187e-02,
          -2.2884e-02,  4.3920e-03],
         [-9.9281e-02, -1.2864e+00, -5.7269e-02,  ...,  3.2679e-02,
           5.4323e-01,  3.6190e-02],
         [-4.9989e-02, -9.7786e-02, -3.3277e-01,  ...,  6.2352e-01,
           3.8324e-01,  3.7129e-01],
         ...,
         [ 4.2136e-01, -2.2533e-02,  1.4990e-01,  ..., -1.7993e-01,
           4.5745e-01,  1.0380e-01],
         [ 4.4702e-01, -7.1752e-02,  2.8757e-01,  ..., -1.4331e-01,
           4.0562e-01, -1.1751e-01],
         [ 7.0385e-01, -1.9483e-02, -1.4968e-04,  ...,  6.3797e-02,
           5.4001e-01, -1.4293e-01]],
        [[-9.4856e-03,  2.7442e-02, -2.8530e-02,  ..., -2.4561e-02,
          -1.7103e-02, -2.4945e-03],
         [-9.2903e-01, -1.1059e-01, -1.6937e-01,  ...,  8.9770e-01,
          -3.3179e-01, -1.0123e-02],
         [-4.9739e-01,  6.8580e-02,  5.0527e-01,  ..., -6.4339e-01,
           8.0251e-01,  3.6361e-01],
         ...,
         [ 3.7872e-01, -2.1182e-01,  2.3512e-01,  ..., -2.7480e-01,
           6.5578e-01, -1.2633e-01],
         [ 4.6661e-01, -1.2451e-01,  9.2595e-02,  ..., -1.1132e-01,
           3.8931e-01, -1.3153e-01],
         [ 6.5851e-01, -7.3548e-02,  8.3549e-02,  ...,  7.9496e-02,
           1.8247e-01,  1.1413e-01]],
        ...,
        [[-7.7943e-03,  1.1077e-02, -4.2613e-02,  ..., -6.0420e-03,
          -2.1543e-02,  2.4686e-02],
         [-7.0415e-02, -3.5605e-01, -3.7115e-01,  ...,  5.9742e-01,
          -6.3677e-01,  5.7255e-01],
         [-2.3269e-01, -6.1453e-01,  1.1919e-01,  ..., -3.8615e-01,
           8.8292e-01, -5.7462e-01],
         ...,
         [ 1.7453e-01, -2.0023e-01,  1.3112e-01,  ..., -1.8684e-01,
           4.1781e-01,  1.5604e-02],
         [ 4.5720e-01, -8.7839e-02,  1.1835e-01,  ..., -1.5116e-01,
           3.9471e-01, -2.1654e-01],
         [ 7.0028e-01,  1.2717e-01,  7.4076e-02,  ...,  3.7161e-02,
           2.3389e-01, -2.4672e-01]],
        [[-5.3709e-03,  1.9278e-03, -4.6725e-02,  ..., -1.0345e-02,
          -2.2363e-02,  1.2240e-02],
         [-1.4934e-01, -3.9352e-01, -9.0427e-02,  ..., -5.0534e-01,
           9.3301e-01,  1.9376e-01],
         [ 4.6906e-01, -9.9231e-02,  7.7901e-02,  ..., -7.9494e-02,
          -2.0084e-01,  2.1212e-01],
         ...,
         [ 7.6340e-01, -4.1879e-01, -4.5021e-01,  ..., -3.2935e-01,
           1.9082e-01, -2.5790e-01],
         [ 1.8871e-01,  8.6386e-02,  9.2135e-02,  ..., -2.1863e-01,
          -2.3733e-03,  1.0450e-01],
         [ 2.8342e-01,  1.7835e-01,  1.0690e-01,  ..., -1.4777e-01,
           1.9169e-01,  2.9702e-01]],
        [[-4.0536e-03,  5.3688e-03, -4.5196e-02,  ..., -9.8453e-03,
          -2.8495e-02,  1.5394e-02],
         [-4.4395e-01, -7.6135e-01, -8.6643e-01,  ...,  7.0317e-01,
          -4.1907e-01, -1.2593e-01],
         [-1.4377e-01, -2.2556e-01,  2.8939e-01,  ...,  4.0058e-01,
           5.5767e-01, -2.0260e-01],
         ...,
         [ 7.9759e-02, -1.5705e-01,  4.6438e-01,  ...,  1.1645e-01,
           7.0245e-01, -2.0029e-01],
         [ 2.0798e-01,  1.1087e-01,  1.4287e-01,  ..., -2.0526e-01,
          -4.1217e-02,  7.0287e-02],
         [ 1.7775e-01,  1.7633e-01,  3.4262e-01,  ..., -1.3698e-01,
           2.5512e-01,  1.0847e-01]]], device='cuda:0'), tensor([[[-0.0140,  0.0262, -0.0623,  ...,  0.0064, -0.0526,  0.0176],
         [-0.9431, -0.3337,  0.2673,  ..., -0.2444, -0.3376,  0.1322],
         [-0.2926, -0.2892, -0.1674,  ..., -0.6528, -0.2172,  0.3120],
         ...,
         [ 0.0564, -0.1810,  0.0444,  ..., -0.1902,  0.3989,  0.0672],
         [ 0.1727, -0.0902, -0.0546,  ...,  0.0372,  0.1988, -0.1474],
         [ 0.0831,  0.0745,  0.0613,  ...,  0.0457,  0.1649, -0.1488]],
        [[-0.0071,  0.0704, -0.0663,  ..., -0.0025, -0.0394,  0.0095],
         [-0.4033, -1.1621, -0.3681,  ..., -0.0952,  0.4501,  0.0225],
         [ 0.7326,  0.1528, -0.3436,  ...,  0.4619,  0.3359,  0.1359],
         ...,
         [ 0.1058,  0.0874, -0.0578,  ..., -0.1790,  0.1939, -0.1293],
         [ 0.0868, -0.0632,  0.0826,  ..., -0.1430,  0.2221, -0.1693],
         [ 0.2564, -0.0133, -0.0120,  ...,  0.0221,  0.3269, -0.1861]],
        [[-0.0140,  0.0091, -0.0769,  ..., -0.0367, -0.0503,  0.0054],
         [-0.7188,  0.1480, -0.1605,  ...,  0.9480, -0.2888, -0.4261],
         [-0.3426,  0.0894,  0.5699,  ..., -0.5733,  0.5525,  0.0963],
         ...,
         [ 0.0845, -0.1180,  0.0637,  ..., -0.1345,  0.2835, -0.1822],
         [ 0.0729, -0.1109,  0.0204,  ..., -0.0552,  0.1935, -0.1926],
         [ 0.2140, -0.0821,  0.0291,  ...,  0.0453,  0.0948,  0.0610]],
        ...,
        [[ 0.0246,  0.0097, -0.0270,  ...,  0.0736, -0.0108,  0.0386],
         [-0.0533,  0.0288, -0.2583,  ...,  0.6773, -0.3795,  0.3252],
         [-0.0521, -0.1453,  0.2516,  ..., -0.3223,  0.7165, -0.1978],
         ...,
         [-0.0799, -0.1553, -0.1259,  ..., -0.1422,  0.3113, -0.1526],
         [ 0.2172, -0.0394, -0.0797,  ..., -0.0789,  0.2318, -0.2615],
         [ 0.2754,  0.1616, -0.0313,  ...,  0.0260,  0.1283, -0.1582]],
        [[-0.0033,  0.0254, -0.0596,  ..., -0.0071, -0.0408,  0.0049],
         [-0.0411, -0.2523, -0.0985,  ..., -0.4587,  0.8377,  0.1575],
         [ 0.4874, -0.1034, -0.2416,  ..., -0.2255, -0.3063, -0.0246],
         ...,
         [ 0.7584, -0.1276, -0.4471,  ..., -0.3969,  0.0662, -0.2530],
         [ 0.0576, -0.0949,  0.1227,  ..., -0.2033, -0.0140,  0.0731],
         [-0.0155,  0.1106, -0.1319,  ...,  0.0552,  0.0173,  0.1846]],
        [[-0.0177,  0.0816, -0.0606,  ...,  0.0126, -0.0444,  0.0127],
         [-0.4128, -0.3095, -0.6509,  ...,  0.5269, -0.3653, -0.0159],
         [-0.2226, -0.0722,  0.0126,  ...,  0.4458,  0.5721, -0.4994],
         ...,
         [ 0.2237,  0.2654,  0.2890,  ..., -0.4460,  0.1692, -0.5162],
         [ 0.1255, -0.1170,  0.2070,  ..., -0.3575, -0.0702,  0.0327],
         [-0.0356,  0.0685, -0.1282,  ...,  0.0806,  0.0482,  0.1575]]],
       device='cuda:0'), tensor([[[-3.0785e-02,  1.0781e-02, -3.7640e-02,  ..., -4.2350e-02,
          -1.7988e-02,  4.5484e-02],
         [-9.8023e-01, -2.9864e-01,  4.0564e-01,  ..., -1.5641e-01,
          -5.0689e-01,  2.5128e-01],
         [-2.9756e-01, -8.9908e-02, -6.6264e-01,  ..., -1.0693e+00,
          -7.3413e-01, -5.9920e-02],
         ...,
         [-1.1523e-01, -1.0379e-01, -1.5429e-01,  ..., -2.7412e-01,
           3.6705e-01,  5.6559e-02],
         [ 6.7628e-02, -3.1548e-02, -1.5942e-01,  ..., -9.2240e-03,
           1.8803e-01, -6.3481e-02],
         [ 5.1150e-02,  1.8358e-01, -1.4752e-01,  ..., -1.3485e-02,
           1.8023e-01, -1.1049e-01]],
        [[-4.8813e-02, -7.4485e-04, -6.3713e-02,  ...,  9.2647e-04,
          -3.0365e-02,  3.9184e-02],
         [-3.3828e-01, -1.4854e+00, -3.7166e-01,  ..., -1.3438e-01,
           4.1644e-01,  4.0724e-01],
         [ 6.2836e-02,  4.9847e-01, -5.9272e-01,  ...,  7.0402e-01,
           7.2149e-02, -2.8624e-01],
         ...,
         [-3.5868e-02,  5.5774e-02, -1.4345e-01,  ..., -3.4166e-01,
           1.9548e-01,  2.7510e-02],
         [ 3.1664e-02, -5.0990e-02, -2.2782e-02,  ..., -1.8013e-01,
           1.5675e-01, -5.4298e-02],
         [ 7.4660e-02, -2.6494e-03, -9.8820e-02,  ..., -7.0112e-03,
           2.8147e-01, -4.7613e-02]],
        [[ 2.5714e-02, -5.6746e-02, -1.0566e-01,  ...,  2.7735e-02,
          -2.2706e-02,  1.0959e-01],
         [-6.7781e-01, -1.4456e-01, -2.0300e-01,  ...,  8.1786e-01,
          -4.2305e-01, -3.6064e-01],
         [-5.7061e-01,  1.9757e-02,  5.4418e-01,  ..., -7.6589e-01,
           5.6884e-01, -4.8757e-03],
         ...,
         [-7.2442e-02, -1.0506e-01, -5.7770e-02,  ..., -1.9991e-01,
           2.8478e-01, -2.5586e-02],
         [-8.9539e-02, -6.5423e-02, -1.0824e-01,  ..., -1.3107e-01,
           1.7652e-01, -9.8158e-02],
         [ 1.1753e-01,  2.2859e-02, -9.8008e-02,  ...,  3.6129e-02,
           3.8225e-02,  1.4424e-01]],
        ...,
        [[ 4.8526e-02,  3.5655e-02, -8.3675e-02,  ...,  1.2889e-01,
           3.0956e-02, -6.7530e-02],
         [ 1.2962e-01,  2.2694e-01, -2.9959e-01,  ...,  7.7407e-01,
          -5.5394e-01,  6.5891e-01],
         [ 1.4722e-01,  2.4236e-01,  6.3353e-01,  ..., -2.2073e-01,
           5.1969e-01, -3.5364e-01],
         ...,
         [-1.9081e-01, -1.1986e-01, -1.4199e-01,  ..., -1.9338e-01,
           3.1937e-01, -6.2380e-02],
         [ 4.8633e-02, -6.8439e-02, -1.5565e-01,  ..., -1.2073e-01,
           1.7405e-01, -1.7165e-01],
         [ 1.5387e-02,  1.6683e-01, -1.1097e-01,  ...,  9.2063e-02,
           1.9029e-01, -7.3310e-02]],
        [[-3.6566e-02, -7.3738e-03, -5.7493e-02,  ..., -9.8974e-03,
          -1.7822e-02,  1.1943e-02],
         [-1.3387e-01, -1.7528e-01, -1.1765e-01,  ..., -3.0426e-01,
           6.8064e-01,  3.9814e-01],
         [ 2.6669e-01,  2.4217e-02, -1.0761e-01,  ..., -4.7108e-01,
          -5.1110e-01, -1.2929e-02],
         ...,
         [ 5.3549e-01, -3.6885e-02, -5.0928e-01,  ..., -3.8385e-01,
           1.1633e-01, -1.2892e-01],
         [-1.1065e-03, -8.7133e-02,  1.0111e-01,  ..., -2.3232e-01,
           1.0891e-01,  7.7614e-02],
         [-7.7499e-02,  3.3031e-02, -7.6443e-02,  ...,  4.4174e-02,
           1.4688e-02,  1.5423e-01]],
        [[ 5.0174e-02,  2.3190e-02, -1.9363e-02,  ...,  7.2205e-02,
          -3.5197e-02,  6.3642e-03],
         [-3.3229e-01, -2.9353e-01, -6.0395e-01,  ...,  5.4081e-01,
          -3.9144e-01,  3.1727e-01],
         [-2.5864e-01, -3.7104e-01, -9.9641e-02,  ...,  5.4929e-01,
           6.5704e-01, -7.6963e-01],
         ...,
         [ 6.9344e-02,  2.3659e-01,  1.9239e-01,  ..., -6.2472e-01,
           3.3624e-01, -2.7422e-01],
         [ 8.8802e-02, -5.3989e-02,  4.3167e-02,  ..., -4.0687e-01,
          -4.5294e-03,  1.0684e-01],
         [-7.3526e-02,  2.0821e-02, -9.2806e-02,  ...,  4.8728e-02,
           1.0255e-02,  1.0988e-01]]], device='cuda:0'), tensor([[[ 5.5093e-03, -1.5836e-03, -3.6407e-02,  ..., -1.5458e-03,
           5.8724e-03,  3.1724e-02],
         [-1.0218e+00, -1.5333e-01,  2.0547e-01,  ...,  2.2489e-01,
          -4.3774e-01, -1.6268e-01],
         [ 2.2793e-01, -2.6391e-01, -6.1371e-01,  ..., -8.8002e-01,
          -4.8820e-01, -2.7153e-02],
         ...,
         [-7.1799e-02, -8.6914e-03, -2.0163e-01,  ..., -1.8610e-01,
           4.5419e-01,  9.2039e-02],
         [-1.8891e-02, -1.9204e-02, -1.8362e-01,  ..., -6.3355e-03,
           2.1008e-01, -7.5486e-02],
         [ 1.3989e-01,  1.9813e-01, -1.1111e-01,  ...,  1.2780e-01,
           1.7949e-01, -1.0461e-01]],
        [[-1.0490e-02, -1.5781e-02, -4.0207e-02,  ..., -1.1044e-02,
          -4.3493e-02,  7.9871e-02],
         [-2.9401e-01, -9.6045e-01, -4.9952e-01,  ...,  1.8562e-02,
           2.2841e-01,  8.5704e-03],
         [ 1.8134e-01,  1.7929e-01, -5.7857e-01,  ...,  5.9875e-01,
          -2.1047e-01,  2.1005e-02],
         ...,
         [-3.7165e-02, -1.9523e-02, -8.4551e-02,  ..., -3.1845e-01,
           1.9899e-01,  2.7591e-02],
         [ 1.1352e-02, -8.8928e-02,  4.9046e-02,  ..., -1.4548e-01,
           1.1092e-01, -4.7463e-02],
         [ 3.5839e-02, -4.4557e-02, -9.7033e-02,  ..., -3.6780e-02,
           2.6624e-01, -1.1798e-01]],
        [[ 1.8313e-02, -3.1739e-02, -2.7352e-02,  ...,  2.8318e-02,
          -3.5111e-02,  5.4737e-02],
         [-1.0620e+00, -3.6185e-01, -2.2813e-01,  ...,  1.0827e+00,
          -1.2381e-01, -5.3416e-01],
         [ 1.0166e-01, -1.9712e-02,  5.1179e-01,  ..., -6.5615e-01,
           6.3827e-01,  4.5117e-02],
         ...,
         [-3.4109e-02, -2.8574e-02, -9.3792e-04,  ..., -1.2751e-01,
           3.4895e-01,  6.2555e-02],
         [-7.3143e-02, -4.0821e-02,  9.7998e-04,  ..., -1.0777e-01,
           2.1020e-01, -8.7572e-02],
         [ 9.4132e-02,  1.7711e-02, -2.0099e-02,  ...,  1.4414e-01,
           6.5521e-02, -1.9209e-02]],
        ...,
        [[ 4.5376e-02,  6.5967e-03, -9.7898e-02,  ...,  8.6558e-02,
          -6.3966e-03,  1.1522e-02],
         [ 1.6391e-02, -1.0203e-01, -3.9516e-01,  ...,  9.4771e-01,
          -4.4335e-01,  3.1183e-01],
         [ 1.0101e-01,  2.8762e-01,  6.8194e-01,  ..., -1.7455e-01,
           6.1788e-01, -1.6604e-02],
         ...,
         [-1.2523e-01, -3.2936e-02, -1.4960e-01,  ..., -1.4226e-01,
           4.0557e-01, -9.0310e-02],
         [ 1.7703e-02, -6.0679e-02, -1.1096e-01,  ..., -1.2184e-01,
           2.3710e-01, -6.9349e-02],
         [-1.1805e-02,  1.5381e-01, -1.5350e-01,  ...,  1.4098e-01,
           2.0721e-01, -8.7953e-03]],
        [[-1.4607e-02, -9.8717e-03, -2.6371e-02,  ..., -5.1353e-02,
          -1.1933e-02,  6.0655e-02],
         [-2.5362e-01, -3.7791e-02, -1.1667e-01,  ..., -1.1099e-01,
           6.8887e-01, -1.0042e-01],
         [ 2.4020e-01, -2.8512e-01, -6.9395e-02,  ..., -5.3200e-01,
          -3.9124e-01,  4.6257e-02],
         ...,
         [ 3.5318e-01,  1.6934e-03, -4.8763e-01,  ..., -2.9517e-01,
           7.8855e-02,  8.2672e-02],
         [-4.1735e-02, -8.7134e-02,  9.0434e-03,  ..., -2.3370e-01,
           7.7721e-02,  4.7515e-01],
         [-9.9010e-02,  2.5593e-02, -4.5859e-02,  ...,  2.3263e-02,
           8.0128e-03,  1.3340e-01]],
        [[ 9.0786e-03, -3.2000e-02, -1.7959e-02,  ...,  1.6479e-02,
          -5.4349e-03,  3.1204e-02],
         [-2.9080e-01, -1.4036e-01, -5.1761e-01,  ...,  5.8776e-01,
          -2.9635e-01,  1.5397e-01],
         [-2.6285e-02, -3.3873e-01,  5.3658e-02,  ...,  6.9253e-01,
           3.8972e-01, -2.0726e-01],
         ...,
         [ 1.2303e-01, -4.0987e-02, -5.8313e-02,  ..., -6.3429e-01,
           3.3039e-01, -1.8440e-01],
         [-9.9580e-02, -2.2564e-01, -1.2378e-01,  ..., -2.5513e-01,
          -9.7540e-03,  3.0635e-01],
         [-5.3274e-02,  9.1220e-03, -5.9519e-02,  ...,  5.6696e-02,
           6.6424e-02,  1.9375e-01]]], device='cuda:0'), tensor([[[-9.2986e-03, -3.3343e-02, -6.9639e-02,  ...,  5.7474e-02,
           2.1736e-04,  3.3198e-02],
         [-7.3650e-01,  1.6845e-01,  5.2209e-01,  ...,  1.7639e-01,
          -3.5019e-01, -6.8275e-02],
         [-1.3057e-01, -1.2829e-01, -3.4445e-01,  ..., -1.0635e+00,
          -4.9525e-01,  6.7815e-01],
         ...,
         [ 1.3033e-02, -8.0483e-02, -1.9926e-01,  ..., -2.4073e-01,
           5.6782e-01, -2.2920e-02],
         [ 2.5464e-02,  1.4159e-02, -2.3359e-01,  ..., -7.3433e-02,
           2.9106e-01, -4.5674e-02],
         [ 6.4162e-02,  1.0371e-01, -1.8988e-01,  ...,  5.0798e-02,
           2.6985e-01,  3.4234e-02]],
        [[-1.8623e-02, -7.0685e-02, -5.0752e-02,  ...,  5.0749e-02,
          -3.0266e-03,  4.2149e-02],
         [-2.0257e-01, -8.9981e-01, -7.0430e-01,  ..., -1.0815e-01,
           1.7627e-01,  2.4232e-01],
         [ 2.4653e-02,  3.2804e-01, -5.0644e-01,  ...,  6.4536e-01,
          -3.1908e-01, -1.9133e-01],
         ...,
         [-8.0691e-02, -3.9058e-02, -1.6378e-01,  ..., -3.7236e-01,
           2.6449e-01, -2.3781e-03],
         [ 5.0639e-03, -1.0896e-01, -1.1231e-02,  ..., -1.8025e-01,
           2.2874e-01,  1.7779e-02],
         [-8.9005e-04, -9.3755e-02, -1.1924e-01,  ..., -9.1860e-02,
           3.6191e-01, -3.3392e-02]],
        [[-5.4185e-02, -5.0115e-02, -6.8665e-02,  ...,  7.7942e-02,
           1.9593e-04,  3.2102e-02],
         [-1.8020e-01, -9.4301e-02, -2.2886e-01,  ...,  8.0187e-01,
           8.8672e-02, -9.2542e-02],
         [-2.3745e-01,  7.1153e-01,  3.0766e-01,  ..., -7.5888e-01,
           4.7723e-01, -1.7912e-03],
         ...,
         [ 1.2724e-02, -1.0993e-01, -7.4723e-02,  ..., -1.2238e-01,
           4.3772e-01,  9.2046e-02],
         [-1.6440e-03, -5.8224e-02, -6.5185e-03,  ..., -9.8302e-02,
           3.3205e-01, -5.9430e-02],
         [ 1.0541e-01,  6.2075e-02, -9.3900e-02,  ...,  1.7634e-01,
           9.8533e-02, -2.0571e-02]],
        ...,
        [[ 2.3822e-03, -5.8202e-02, -1.5208e-01,  ...,  1.2135e-01,
          -4.6595e-02,  4.8956e-03],
         [ 8.2966e-02,  3.6539e-02, -5.6795e-01,  ...,  8.8796e-01,
          -5.4226e-01,  2.5110e-01],
         [ 2.7192e-02, -2.9929e-02,  5.8136e-01,  ..., -7.4323e-02,
           6.1270e-01,  2.6213e-01],
         ...,
         [-9.1811e-02,  4.2610e-02, -1.5455e-01,  ..., -1.1963e-01,
           4.6909e-01, -6.8555e-02],
         [-2.4249e-02, -3.1187e-02, -1.0444e-01,  ..., -4.4783e-02,
           3.0954e-01, -8.0460e-02],
         [ 1.2387e-01,  1.8230e-01, -2.8871e-01,  ...,  2.1680e-01,
           2.3282e-01,  2.0721e-02]],
        [[ 1.3380e-02, -3.6838e-02, -6.5357e-02,  ...,  5.2285e-02,
          -3.0436e-02,  1.2620e-02],
         [ 2.8190e-01,  3.4675e-01, -5.6214e-02,  ..., -1.0049e-01,
           8.3953e-01, -1.9564e-02],
         [-8.4241e-02, -1.4921e-01, -9.3387e-02,  ..., -4.7213e-01,
          -5.8177e-01,  1.0789e-02],
         ...,
         [ 4.5846e-01,  5.1294e-01, -7.0654e-01,  ..., -7.2898e-02,
           3.9469e-01, -1.5399e-01],
         [ 6.3581e-02, -9.9377e-02, -5.0086e-02,  ..., -1.8457e-01,
           1.3090e-01,  1.6048e-01],
         [-6.8317e-02, -1.8136e-02, -1.1610e-02,  ...,  6.8074e-02,
          -2.5731e-03,  6.1551e-02]],
        [[-3.4079e-02, -6.9238e-02, -1.0004e-01,  ...,  7.1494e-02,
          -9.4942e-03,  3.4559e-03],
         [ 1.8730e-01,  4.3681e-01, -3.7469e-01,  ...,  5.2993e-01,
          -2.8741e-01,  1.5637e-01],
         [-1.8915e-01, -2.5346e-02, -2.2775e-01,  ...,  1.4662e-01,
           3.5502e-01, -1.5039e-01],
         ...,
         [ 1.9872e-01, -3.2797e-02, -3.9968e-01,  ..., -4.7750e-01,
           3.4109e-01, -3.8241e-01],
         [-1.5427e-01, -1.9731e-01, -2.0108e-01,  ..., -1.4807e-01,
          -4.8212e-03,  8.3919e-02],
         [-9.9337e-02, -3.6288e-03, -5.7992e-03,  ...,  6.3517e-02,
           6.1408e-02,  7.3305e-02]]], device='cuda:0'), tensor([[[-0.0317, -0.0645, -0.0932,  ...,  0.0847,  0.0800,  0.0351],
         [-0.5417,  0.4810,  0.5789,  ..., -0.0886, -0.7210, -0.1109],
         [-0.3893, -0.3124, -0.3352,  ..., -1.0213, -1.0548,  0.6043],
         ...,
         [-0.2679, -0.0684, -0.2658,  ..., -0.3064,  0.5239, -0.2415],
         [-0.2836,  0.0415, -0.3098,  ..., -0.2046,  0.1676, -0.0848],
         [ 0.0555, -0.0436, -0.2361,  ..., -0.1056,  0.1941, -0.0984]],
        [[-0.0381, -0.0988, -0.0189,  ...,  0.0831,  0.0619,  0.0309],
         [-0.3909, -0.4898, -0.8044,  ..., -0.1386,  0.4588,  0.3876],
         [ 0.2587,  0.1469, -0.9607,  ...,  0.4155, -0.5767, -0.0281],
         ...,
         [-0.0369,  0.0323, -0.4236,  ..., -0.4445,  0.2081, -0.1637],
         [-0.0878, -0.1310, -0.0477,  ..., -0.2756,  0.1751, -0.0409],
         [-0.2326, -0.0332, -0.1262,  ..., -0.2395,  0.2852, -0.0198]],
        [[-0.0273, -0.0297, -0.0532,  ...,  0.0919,  0.0957,  0.0205],
         [-0.1553,  0.0344, -0.2715,  ...,  0.7610, -0.1966, -0.1498],
         [-0.2658,  0.3933,  0.4090,  ..., -1.0379,  0.4190,  0.0158],
         ...,
         [-0.0901, -0.2032, -0.3142,  ..., -0.3649,  0.3189,  0.0877],
         [-0.1137, -0.0747, -0.2741,  ..., -0.1848,  0.2008, -0.0212],
         [-0.1715, -0.0016, -0.1976,  ...,  0.2255,  0.0984, -0.1400]],
        ...,
        [[-0.0226, -0.1446, -0.0329,  ...,  0.1284,  0.0524, -0.0401],
         [-0.0746, -0.1291, -0.1723,  ...,  0.7746, -0.4676,  0.3873],
         [ 0.1878, -0.3711,  0.8676,  ...,  0.3272,  0.7571,  0.0811],
         ...,
         [-0.2480, -0.0618, -0.1444,  ..., -0.2509,  0.3794, -0.0983],
         [-0.0757, -0.1112, -0.1862,  ..., -0.0660,  0.1627,  0.0736],
         [ 0.1070, -0.0064, -0.3612,  ...,  0.2547,  0.1527,  0.0684]],
        [[-0.0186, -0.0798, -0.0360,  ...,  0.0868,  0.0517,  0.0242],
         [ 0.2969, -0.1132, -0.1104,  ..., -0.0633,  0.5740, -0.1165],
         [ 0.3749, -0.2912,  0.1268,  ..., -0.4179, -0.8749, -0.1773],
         ...,
         [ 0.4531,  0.3933, -0.9792,  ...,  0.0486,  0.3813, -0.0498],
         [ 0.0779,  0.0208, -0.0998,  ..., -0.2078,  0.1107,  0.4358],
         [-0.0714, -0.0317, -0.0023,  ...,  0.0327, -0.0035,  0.0454]],
        [[-0.0224, -0.0810, -0.0360,  ...,  0.0920,  0.0669,  0.0191],
         [ 0.1446,  0.2948, -0.1910,  ...,  0.5505, -0.5148, -0.0367],
         [-0.2413, -0.7669, -0.3651,  ..., -0.1296,  0.2739,  0.2719],
         ...,
         [ 0.1129, -0.2223, -0.4570,  ..., -0.1765,  0.2591, -0.5460],
         [-0.0160, -0.2411, -0.2655,  ..., -0.2874, -0.0535,  0.3953],
         [-0.0460, -0.0136,  0.0230,  ...,  0.0124,  0.0226,  0.0537]]],
       device='cuda:0'), tensor([[[-4.5710e-02, -6.6339e-03,  5.6750e-03,  ...,  8.8035e-02,
           1.0945e-01,  1.2342e-02],
         [-5.2487e-01,  3.8187e-01,  6.9018e-01,  ..., -1.9310e-02,
          -5.6869e-01, -5.1694e-02],
         [-1.7672e-01, -2.6947e-01, -2.5063e-01,  ..., -1.0900e+00,
          -1.2008e+00,  4.8183e-01],
         ...,
         [-3.0673e-01,  2.0819e-01, -2.3605e-01,  ..., -2.9561e-01,
           5.7608e-01, -3.1511e-01],
         [-5.5453e-01,  1.1374e-01, -3.0571e-01,  ..., -3.0388e-01,
           8.9629e-02, -2.0312e-01],
         [ 1.6355e-01, -2.0223e-01, -9.5842e-02,  ..., -1.1037e-01,
          -1.3122e-01, -1.9553e-01]],
        [[-6.9396e-02, -2.2371e-02,  3.9341e-03,  ...,  7.4485e-02,
           9.3627e-02, -1.6947e-02],
         [-2.0142e-01, -1.7326e-01, -1.0743e+00,  ..., -2.6254e-01,
           3.6687e-01,  3.3842e-01],
         [ 3.2925e-01,  2.3249e-01, -7.3905e-01,  ...,  1.8079e-01,
          -7.1996e-01, -4.7360e-02],
         ...,
         [-5.1310e-02,  1.0610e-01, -3.0782e-01,  ..., -4.0922e-01,
          -9.1790e-02, -3.1442e-01],
         [-2.2785e-01, -3.8601e-01,  2.4755e-03,  ...,  3.6167e-02,
           1.7060e-01, -2.9117e-01],
         [-2.6201e-01, -4.5576e-02, -1.8137e-01,  ..., -2.1133e-01,
           3.1549e-01, -3.5142e-01]],
        [[-7.8135e-02, -3.4808e-02,  2.2163e-02,  ...,  6.6389e-02,
           1.1104e-01, -1.2425e-02],
         [-1.7499e-01,  2.2805e-01, -7.1213e-02,  ...,  5.7162e-01,
          -5.3358e-01,  1.0977e-01],
         [-3.5911e-01,  2.1955e-01,  5.8418e-01,  ..., -1.1861e+00,
           6.2679e-01,  3.9571e-02],
         ...,
         [-3.1916e-01, -1.3961e-01, -2.3153e-01,  ..., -3.2534e-01,
           3.0211e-01, -1.3439e-01],
         [-9.7341e-02, -1.5041e-01, -9.5371e-02,  ..., -1.2506e-01,
           1.0873e-01, -1.4647e-01],
         [-2.7516e-01, -1.5532e-01, -1.6862e-02,  ...,  3.8623e-01,
           5.3138e-02, -3.9913e-01]],
        ...,
        [[-6.2032e-02, -2.1892e-02, -2.3597e-04,  ...,  8.1578e-02,
           8.5973e-02, -1.7294e-02],
         [-1.5625e-01,  4.1248e-01, -2.9982e-01,  ...,  4.8050e-01,
          -5.1174e-01,  2.5168e-01],
         [ 1.2218e-01, -3.0575e-01,  7.3241e-01,  ...,  1.5186e-01,
           3.1720e-01, -1.9657e-01],
         ...,
         [-2.6285e-01,  3.1104e-01, -1.3429e-01,  ..., -1.9460e-01,
           2.8259e-01, -4.3585e-01],
         [-1.9764e-01,  1.4989e-01, -1.9629e-01,  ..., -5.5011e-02,
           1.4460e-01, -2.8546e-01],
         [ 2.5836e-01,  2.7027e-01, -4.3519e-01,  ...,  3.5355e-01,
           2.1552e-01,  7.7251e-02]],
        [[-6.7437e-02, -1.7460e-02,  6.6154e-03,  ...,  6.8605e-02,
           8.2957e-02, -3.8215e-03],
         [ 4.6884e-01, -1.7804e-01, -1.1384e-01,  ...,  6.9277e-02,
           5.0200e-01, -2.6485e-01],
         [ 5.0735e-01, -6.9355e-01,  2.2587e-01,  ..., -6.6233e-01,
          -8.7977e-01, -3.3591e-02],
         ...,
         [ 4.3378e-01,  2.6032e-03, -1.1197e+00,  ...,  2.0986e-01,
          -3.8361e-02, -1.8601e-02],
         [-1.2576e-01,  2.2569e-01, -2.2373e-01,  ..., -1.2370e-01,
           1.4073e-01,  2.3484e-01],
         [-6.6889e-02, -2.7071e-02,  4.8898e-02,  ...,  2.9860e-02,
          -4.7715e-02, -1.7362e-02]],
        [[-5.8159e-02, -2.4665e-02,  1.0494e-02,  ...,  7.7469e-02,
           8.6799e-02, -5.9089e-03],
         [ 4.3282e-01,  2.8968e-01,  1.0461e-01,  ...,  6.1890e-01,
          -7.0774e-01, -1.6194e-01],
         [-3.8844e-01, -2.2064e-01, -3.6528e-01,  ..., -3.4549e-01,
           3.0834e-01,  4.3735e-01],
         ...,
         [ 4.0980e-01,  7.4361e-01, -5.4817e-01,  ...,  5.9094e-01,
          -1.8832e-01, -1.2166e-01],
         [-3.7606e-02,  2.8113e-02, -5.5400e-01,  ..., -5.3789e-02,
          -2.0249e-02,  1.8077e-01],
         [-6.0051e-02, -1.9144e-03,  5.0782e-02,  ...,  3.5368e-02,
          -1.4745e-02,  1.7575e-02]]], device='cuda:0'), tensor([[[ 4.7642e-02,  1.0767e-01, -3.0309e-01,  ..., -8.6264e-02,
           3.1254e-01,  1.4160e-02],
         [-2.0256e-01,  2.0243e-02,  7.3825e-01,  ...,  2.9937e-02,
          -5.1516e-01, -1.1289e-01],
         [ 1.0771e-02, -4.5373e-01, -4.6537e-02,  ..., -1.2889e+00,
          -9.1886e-01,  5.0561e-01],
         ...,
         [-1.9385e-02,  1.8876e-01, -2.6523e-01,  ..., -5.4656e-01,
           6.6734e-01, -4.1987e-01],
         [-4.5753e-01,  4.5992e-01, -2.0188e-01,  ..., -6.2337e-01,
           1.3532e-01, -1.2830e-01],
         [ 4.8323e-01,  3.2340e-01,  1.1910e-01,  ..., -2.3589e-01,
          -2.5021e-02,  3.6517e-02]],
        [[-2.5052e-02,  1.0663e-01, -2.2800e-01,  ..., -6.7385e-02,
           2.8487e-01, -1.0473e-01],
         [ 2.8779e-02, -3.1796e-01, -1.0626e+00,  ..., -5.8020e-01,
           1.9046e-01, -4.2840e-02],
         [ 8.5302e-01,  1.5726e-01, -5.8759e-01,  ..., -4.5488e-02,
          -4.2263e-01, -1.5592e-01],
         ...,
         [ 3.2052e-01,  5.6110e-02, -4.3630e-02,  ..., -5.5559e-01,
          -4.6228e-02, -1.1119e-01],
         [-2.9020e-01, -3.7602e-01,  1.0122e-01,  ..., -2.9685e-02,
           2.9526e-01,  1.4413e-01],
         [-5.0761e-02, -1.1139e-01, -1.2001e-02,  ..., -1.9938e-01,
           3.6249e-01, -9.7080e-02]],
        [[-4.3224e-02,  9.2397e-02, -2.2346e-01,  ...,  2.1485e-02,
           1.1334e-01, -1.4643e-01],
         [-1.3390e-01, -7.7754e-02,  6.3053e-02,  ...,  6.5104e-01,
          -4.9886e-01, -3.2269e-01],
         [-2.5223e-01, -2.3874e-01,  2.2723e-01,  ..., -1.7590e+00,
           3.3238e-01,  4.7696e-02],
         ...,
         [-2.3755e-01,  3.2745e-01, -2.5376e-01,  ..., -3.6832e-01,
           7.2931e-01, -2.4852e-01],
         [-3.2490e-02,  3.7596e-01, -9.8083e-02,  ..., -2.4726e-01,
           1.6900e-01, -1.6677e-01],
         [-3.3700e-01,  1.4344e-01,  1.4410e-01,  ...,  3.9551e-01,
           1.6998e-01, -5.5712e-01]],
        ...,
        [[-5.6658e-03,  7.6578e-02, -2.5735e-01,  ...,  5.9257e-02,
           2.7483e-01, -1.3960e-01],
         [-6.0038e-01,  1.0309e-01, -1.9952e-01,  ...,  5.4909e-01,
          -4.2409e-01, -6.2690e-02],
         [-2.1143e-02, -3.4268e-01,  6.2385e-01,  ..., -1.1553e-01,
           4.3065e-01, -9.3627e-02],
         ...,
         [ 2.6922e-02,  1.5216e-01, -2.4005e-01,  ..., -8.3936e-02,
           2.4872e-01, -4.7881e-01],
         [-8.5496e-02,  1.7043e-01, -7.9450e-02,  ..., -8.7421e-02,
           3.7215e-01, -3.7382e-01],
         [ 2.7570e-01,  2.0377e-01, -2.9097e-01,  ...,  3.7044e-01,
           1.9065e-01,  4.0025e-02]],
        [[ 7.0914e-03,  3.9171e-02, -2.5180e-01,  ..., -8.5759e-02,
           3.0253e-01, -1.2945e-02],
         [ 4.5487e-01, -3.9128e-01, -2.2156e-01,  ..., -5.9573e-02,
           6.0588e-01, -3.7807e-01],
         [ 3.5085e-01,  1.0464e-01,  1.4964e-01,  ..., -3.5320e-01,
          -9.1100e-01,  4.4211e-01],
         ...,
         [ 3.9684e-01, -5.5115e-03, -1.4696e+00,  ...,  4.3748e-01,
          -7.9682e-02, -2.4198e-01],
         [-1.2606e-01, -2.4393e-02, -2.0682e-01,  ...,  2.8116e-02,
           5.0680e-01,  4.0671e-01],
         [-5.9235e-02, -5.3011e-02,  5.4986e-02,  ..., -1.4230e-04,
          -1.6612e-02,  3.6775e-03]],
        [[-5.7817e-02,  1.1067e-01, -2.7861e-01,  ..., -7.4791e-02,
           2.9121e-01, -1.1324e-01],
         [ 4.9591e-01,  4.1980e-03,  1.3675e-01,  ...,  8.4658e-01,
          -5.3522e-01, -6.4723e-02],
         [-7.5505e-01, -2.0223e-01, -1.6455e-01,  ..., -5.7394e-01,
           7.1738e-01,  2.0871e-01],
         ...,
         [ 5.5574e-01,  1.4283e-01, -9.9441e-01,  ...,  7.4595e-01,
           1.5965e-01, -7.3423e-01],
         [ 7.1215e-03, -4.0926e-03, -4.6490e-01,  ...,  2.2192e-01,
           2.0483e-01,  3.0117e-01],
         [-4.5028e-02, -3.9239e-02,  9.5359e-02,  ...,  4.6591e-02,
          -6.6907e-02,  4.9517e-02]]], device='cuda:0'), tensor([[[-0.0604,  0.6928, -0.0573,  ..., -0.1272,  0.1400, -0.2066],
         [-0.0555, -0.1345,  0.8800,  ...,  0.0557, -0.6325, -0.2764],
         [ 0.1536, -0.4270,  0.0983,  ..., -1.3926, -0.7951,  0.0184],
         ...,
         [ 0.0984,  0.5757, -0.3937,  ..., -0.4746,  0.9365, -0.3295],
         [-0.3132,  0.7743, -0.1806,  ..., -0.6394,  0.1582, -0.2164],
         [ 0.7722,  0.0971,  0.0889,  ..., -0.2594,  0.2809, -0.1050]],
        [[-0.2645, -0.3906,  0.0663,  ...,  0.0641,  0.2161,  0.1952],
         [-0.1327, -0.5482, -0.9647,  ..., -0.0974,  0.5568, -0.1363],
         [ 0.6912,  0.1732, -0.6591,  ..., -0.1901, -0.1764, -0.0015],
         ...,
         [ 0.1816,  0.0795, -0.2791,  ..., -0.7791,  0.0347, -0.1838],
         [-0.1753, -0.4877,  0.0555,  ...,  0.3280,  0.1945, -0.2613],
         [-0.3883, -0.1827, -0.1245,  ..., -0.1102,  0.4397, -0.2591]],
        [[ 0.1730,  0.2711, -0.1275,  ..., -0.2824,  0.2034,  0.1588],
         [-0.2026, -0.1906,  0.0035,  ...,  0.4223, -0.3820, -0.4241],
         [ 0.3914,  0.4688,  0.4219,  ..., -1.3012,  0.1203, -0.0591],
         ...,
         [-0.2890,  0.1309, -0.3556,  ..., -0.2612,  0.7084, -0.4882],
         [ 0.3102, -0.0679, -0.2260,  ..., -0.2049, -0.3048, -0.7379],
         [ 0.0426,  0.1681,  0.0116,  ...,  0.6564,  0.1064, -0.5013]],
        ...,
        [[ 0.1952,  0.2696, -0.3462,  ..., -0.1784,  0.0395,  0.0016],
         [-0.5364, -0.0555, -0.3525,  ...,  0.3383, -0.5456,  0.2853],
         [-0.4245,  0.1761,  0.2167,  ..., -0.0850,  0.7629,  0.0819],
         ...,
         [-0.1640,  0.2344, -0.4113,  ..., -0.1038,  0.3380, -0.7223],
         [-0.0382,  0.0835, -0.0405,  ..., -0.0426,  0.5432, -0.7603],
         [ 0.7672,  0.2592, -0.5825,  ...,  0.2231,  0.1855,  0.0149]],
        [[ 0.1089, -0.0610, -0.4857,  ..., -0.1656,  0.1399,  0.2924],
         [ 0.7148, -0.3538, -0.0969,  ..., -0.2519,  0.5421, -0.0136],
         [ 0.5439,  0.0173,  0.0953,  ...,  0.2300, -0.7816, -0.0365],
         ...,
         [ 0.3563,  0.1286, -1.1178,  ...,  0.4707,  0.0081, -0.8324],
         [-0.1793,  0.1621, -0.3039,  ..., -0.2184,  0.6935, -0.0821],
         [-0.1027, -0.0267,  0.0264,  ...,  0.0179,  0.0274, -0.0292]],
        [[-0.0393,  0.3880, -0.1297,  ..., -0.0359,  0.3735,  0.1092],
         [ 0.5865, -0.2157,  0.0762,  ...,  0.4822, -0.2576, -0.3754],
         [-0.5842, -0.2268, -0.3470,  ..., -0.1086,  0.4789,  0.1402],
         ...,
         [ 0.0383,  0.2972, -1.0585,  ...,  0.4110,  0.4057, -1.2110],
         [-0.2457, -0.0014, -0.5970,  ..., -0.0260,  0.4424,  0.0894],
         [-0.0793, -0.0515,  0.0358,  ...,  0.0404,  0.0223, -0.0200]]],
       device='cuda:0'), tensor([[[-0.2208,  0.6847, -0.0928,  ..., -0.1342,  0.0319, -0.1170],
         [-0.0947, -0.2903,  0.7154,  ..., -0.1300, -0.4272, -0.0980],
         [ 0.0205, -0.2731,  0.1236,  ..., -1.0331, -0.7618,  0.0232],
         ...,
         [-0.0488,  0.0885, -0.3942,  ..., -0.5870,  0.7498, -0.0040],
         [-0.3321,  0.1269, -0.2411,  ..., -0.4704,  0.3840,  0.0303],
         [ 0.4042,  0.4533,  0.0764,  ..., -0.5184,  0.0177,  0.1791]],
        [[-0.2617, -0.1743,  0.0079,  ..., -0.0076,  0.2433, -0.3427],
         [-0.2898, -0.2864, -0.8895,  ...,  0.0334,  0.5199,  0.1314],
         [ 0.4882, -0.1260, -0.7436,  ...,  0.1713, -0.2959, -0.0885],
         ...,
         [ 0.1499, -0.2611, -0.3279,  ..., -0.2842,  0.4466, -0.1947],
         [ 0.0337, -1.0264, -0.2361,  ...,  0.4704,  0.1023, -0.3891],
         [-0.4749, -0.4904,  0.0539,  ..., -0.1632,  0.3571, -0.0533]],
        [[-0.0429,  0.3932, -0.2627,  ..., -0.0231,  0.1103, -0.0659],
         [-0.4550, -0.3072, -0.0849,  ...,  0.3899, -0.0571, -0.0900],
         [ 0.4286,  0.0283,  0.2240,  ..., -0.8172,  0.0650,  0.4828],
         ...,
         [-0.1106, -0.2971, -0.1739,  ..., -0.1359,  0.9266, -0.2035],
         [ 0.0698,  0.2213, -0.0982,  ...,  0.0300, -0.2168, -0.5127],
         [-0.2604, -0.1291,  0.0671,  ...,  0.5729,  0.1168, -0.5480]],
        ...,
        [[-0.1378,  0.3973, -0.2803,  ...,  0.1148, -0.0382,  0.0739],
         [-0.1429, -0.1300, -0.2961,  ...,  0.4766, -0.3042,  0.0747],
         [-0.2651,  0.0224,  0.1067,  ..., -0.2908,  0.6186,  0.2172],
         ...,
         [-0.0959,  0.1461, -0.4298,  ..., -0.0594,  0.4182, -0.5863],
         [-0.0014, -0.2580, -0.2660,  ..., -0.3074,  0.2533, -0.2901],
         [ 0.6574,  0.4811, -0.6301,  ..., -0.1591,  0.3084, -0.1588]],
        [[-0.1114,  0.3119, -0.5745,  ...,  0.1091,  0.1260,  0.2345],
         [ 0.4858, -0.4220, -0.4696,  ..., -0.1730,  0.6516, -0.0310],
         [ 0.0543,  0.2773, -0.2017,  ...,  0.4089, -0.7013,  0.0730],
         ...,
         [ 0.3140,  0.6943, -1.0518,  ...,  0.4919,  0.0309, -0.6911],
         [ 0.0491,  0.2954, -0.3702,  ...,  0.0217,  0.3827, -0.2415],
         [-0.1381,  0.0127,  0.0350,  ...,  0.0096,  0.0627, -0.0342]],
        [[-0.0429,  0.5894, -0.0441,  ..., -0.0943,  0.1563,  0.0080],
         [ 0.5837, -0.2333, -0.1299,  ...,  0.3626, -0.1390, -0.1362],
         [-0.4617, -0.1104, -0.2045,  ..., -0.1488,  0.2196,  0.1573],
         ...,
         [ 0.1070,  0.6755, -0.6930,  ...,  0.4792,  0.5036, -0.8010],
         [-0.1270,  0.5346, -0.3043,  ..., -0.1049,  0.2323, -0.2593],
         [-0.1128,  0.0023,  0.0303,  ...,  0.0351,  0.0590, -0.0290]]],
       device='cuda:0'), tensor([[[-6.9944e-02, -1.0590e-02,  4.1829e-02,  ...,  1.0043e-02,
           4.7831e-02,  1.0216e-02],
         [-3.0887e-02, -4.0120e-01,  6.6828e-02,  ..., -7.5027e-02,
          -4.8962e-01, -6.8567e-02],
         [-2.0993e-01, -5.4754e-01, -2.3258e-01,  ..., -1.3388e+00,
          -1.1491e+00, -2.3386e-02],
         ...,
         [ 8.1855e-02,  4.3485e-01, -6.5985e-01,  ..., -8.0723e-01,
           8.2609e-01, -2.1100e-01],
         [-3.1698e-01,  2.6257e-02, -2.2413e-01,  ..., -7.2464e-01,
           3.6034e-01, -1.0888e-01],
         [ 1.9187e-01,  2.7482e-01, -1.5396e-03,  ..., -7.8643e-01,
          -2.9671e-01,  8.8141e-02]],
        [[-6.8707e-02, -1.1798e-02,  4.1313e-02,  ...,  1.8970e-02,
           5.1004e-02,  1.0701e-02],
         [-1.1810e-01, -6.7042e-01, -1.0075e+00,  ...,  2.5329e-01,
           2.0501e-01,  8.5152e-03],
         [ 5.8282e-01, -1.8108e-01, -8.7814e-01,  ..., -1.0972e-01,
          -3.0838e-01, -2.0878e-01],
         ...,
         [ 6.5020e-01, -2.2158e-01, -2.5825e-01,  ..., -5.4085e-01,
          -4.2103e-02, -2.9238e-01],
         [ 7.3911e-01, -1.4881e+00, -4.7032e-02,  ...,  1.7163e-01,
           1.8631e-01, -4.1968e-01],
         [-5.2356e-01, -7.5476e-01,  1.1948e-01,  ..., -8.9247e-02,
           4.1243e-01, -2.2752e-01]],
        [[-6.2928e-02, -1.1753e-02,  3.2554e-02,  ...,  2.2654e-02,
           4.5415e-02,  2.3684e-02],
         [-4.3957e-01, -4.0079e-01, -1.1938e-01,  ...,  1.3579e-01,
           7.0195e-02, -8.2761e-02],
         [ 3.2489e-01, -1.3882e-02,  2.6409e-01,  ..., -6.5510e-01,
           1.2417e-01,  2.3871e-01],
         ...,
         [-7.1580e-02, -3.0473e-01,  3.0601e-01,  ..., -3.3527e-01,
           9.9631e-01, -2.1724e-01],
         [ 3.1187e-01,  3.5909e-01,  6.2628e-01,  ...,  2.5551e-01,
          -9.5274e-02, -4.4642e-01],
         [ 3.0015e-01,  3.1804e-01,  4.2096e-01,  ...,  4.6592e-01,
           5.4596e-02, -5.8515e-01]],
        ...,
        [[-6.5681e-02, -2.1882e-03,  3.9807e-02,  ...,  3.2592e-02,
           4.1793e-02,  2.6361e-02],
         [-1.9015e-02, -7.2430e-02, -2.3958e-01,  ...,  2.4037e-01,
          -2.1613e-01,  4.8588e-01],
         [-3.1222e-01, -1.5252e-01,  3.7195e-02,  ..., -5.8217e-01,
           7.3059e-01, -1.8090e-01],
         ...,
         [ 6.7837e-02, -8.3301e-02,  2.9614e-01,  ..., -4.6332e-01,
           7.3811e-01, -6.5263e-01],
         [-5.7688e-02, -4.8960e-01,  2.5260e-01,  ..., -7.0551e-01,
           9.0168e-01, -3.5891e-01],
         [ 7.0275e-01,  3.4850e-01, -3.7657e-01,  ..., -1.0925e+00,
           5.0488e-01, -6.9715e-02]],
        [[-7.7595e-02, -2.6045e-03,  4.0080e-02,  ...,  3.9270e-02,
           5.7416e-02,  1.8193e-02],
         [-1.2218e-02, -3.0771e-01, -4.1003e-01,  ..., -3.8501e-02,
           5.5547e-01, -1.3769e-01],
         [ 1.5206e-01,  2.1966e-01, -4.9368e-01,  ...,  3.5788e-01,
          -5.3335e-01, -2.5242e-02],
         ...,
         [ 3.0909e-01,  5.7683e-01, -6.9894e-01,  ..., -1.2891e-01,
           6.6206e-02, -1.3018e-01],
         [-6.4571e-02, -3.2871e-03,  2.7888e-02,  ...,  2.4940e-02,
           4.4035e-02,  1.2997e-02],
         [-6.8884e-02,  5.8428e-03,  4.0791e-02,  ...,  2.3583e-02,
           6.0290e-02,  8.5030e-04]],
        [[-7.5504e-02,  2.2795e-02,  5.1730e-02,  ...,  9.0280e-03,
           5.3453e-02,  1.2467e-02],
         [ 2.1325e-01, -1.4887e-01, -1.3817e-01,  ...,  2.2312e-01,
          -8.4104e-02,  7.0579e-02],
         [-6.3054e-01,  5.5512e-02, -1.2623e-01,  ..., -3.6121e-01,
          -4.1451e-01,  4.4789e-01],
         ...,
         [ 5.9139e-02,  8.0239e-01, -6.1545e-01,  ...,  1.5397e-01,
          -2.9599e-02, -8.1328e-01],
         [-7.7216e-02, -2.3861e-02,  1.6825e-02,  ...,  8.9363e-03,
           3.7585e-02,  1.2824e-02],
         [-6.9481e-02,  9.3183e-03,  4.0565e-02,  ...,  1.8251e-02,
           6.4276e-02,  1.7806e-02]]], device='cuda:0'), tensor([[[-0.1895,  0.0612, -0.2707,  ..., -1.6133, -1.0165,  0.4967],
         [ 0.1272, -0.3313, -0.3264,  ..., -0.1407, -0.8205,  0.1214],
         [-0.1271,  0.6117, -0.6999,  ..., -1.4933, -2.1855,  1.0228],
         ...,
         [ 0.6361,  1.5219, -0.5623,  ..., -1.9005,  1.0001,  0.5386],
         [ 0.0828,  0.6173, -0.0876,  ..., -1.1722,  0.1739,  0.3600],
         [ 1.0617,  0.9418,  0.4089,  ..., -2.0405, -0.1776,  1.1776]],
        [[ 0.5668,  0.2342, -0.8459,  ...,  1.6194,  0.2559, -0.1441],
         [ 0.7821, -0.2451, -2.4790,  ...,  0.2847,  0.4636,  0.0855],
         [ 1.7590,  0.1984, -1.5857,  ...,  0.7890, -0.8409,  0.6865],
         ...,
         [ 1.9677, -0.5343, -0.4510,  ...,  0.4224, -0.0569, -0.1443],
         [ 1.7805, -2.0624, -0.0990,  ...,  0.6603,  0.6570,  0.1368],
         [-0.0863, -1.2496, -0.2686,  ...,  0.1203,  0.7221, -0.8231]],
        [[-0.7815, -0.0600, -0.5365,  ..., -0.7141, -0.8724, -0.3547],
         [-1.5300, -0.4970, -0.9590,  ...,  0.0963, -0.1013, -1.2735],
         [ 0.4013,  0.3068,  0.5348,  ..., -0.7209,  0.1649,  1.6312],
         ...,
         [-0.2039, -0.2236,  0.3233,  ..., -0.1262,  1.3725,  0.0288],
         [ 1.5785,  1.0562,  1.2657,  ...,  0.5310,  0.7875,  0.6531],
         [ 1.0635,  1.1671,  0.5674,  ...,  0.9865,  0.4514, -0.8051]],
        ...,
        [[ 0.9248,  3.1782,  0.1531,  ..., -1.0358, -0.4163, -0.1604],
         [ 0.7397,  0.8806,  0.0112,  ...,  0.3976, -0.9561,  0.4423],
         [ 0.1883,  1.1716,  0.7222,  ..., -0.4660,  1.1534,  0.2091],
         ...,
         [ 1.0362,  0.4327,  0.5178,  ..., -0.6070,  0.6974, -0.9213],
         [ 1.0321,  0.5675,  0.6878,  ..., -0.3163,  1.3951, -0.4803],
         [ 1.8270,  2.5241,  0.0200,  ..., -1.2686,  0.9468,  0.0054]],
        [[ 1.9404,  0.5265, -0.4706,  ...,  0.3790,  0.8398,  0.9858],
         [ 1.0030,  0.2304, -0.9295,  ..., -0.2662,  1.6351, -0.3480],
         [ 1.4999,  0.9617, -0.7734,  ...,  0.8423, -0.6698,  0.2962],
         ...,
         [ 1.5838,  1.7730, -1.0272,  ..., -0.0078,  0.0445, -0.5024],
         [ 2.0157,  0.2065, -0.5538,  ...,  0.4393, -0.1190,  0.6201],
         [ 1.8370,  0.5399, -0.5878,  ...,  0.3567,  0.2340,  0.3147]],
        [[ 0.0345,  2.2977,  0.3631,  ..., -0.6475, -0.4651, -0.0376],
         [ 0.4407,  0.5963, -0.9371,  ...,  0.6991, -0.0121,  0.5118],
         [-0.4926,  1.5796,  0.2541,  ..., -0.1312, -0.3167,  1.4652],
         ...,
         [ 0.1494,  2.0624,  0.0197,  ...,  0.4759, -0.1942, -1.5431],
         [ 0.1114,  0.3286,  0.5119,  ..., -0.1084, -0.3098, -0.2404],
         [ 0.2715,  2.4727,  0.3201,  ..., -0.5953,  0.5236, -0.2393]]],
       device='cuda:0'))
1: None None
None
None
loading configuration file /fsx/ganayu/experiments/supershaper/aug13_v1_acadbertdata_supernet_retrain_subnet_125Ksteps/supernet_continue/best_model/config.json
/data/home/ganayu/miniconda/envs/basic/lib/python3.8/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.
  warnings.warn(
Model config BertConfig {
  "_name_or_path": "/fsx/ganayu/experiments/supershaper/aug9_acadbertdata_supernet_v1/acav1/best_model",
  "additional_random_softmaxing": false,
  "alpha_divergence": 0,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bottleneck_rank": 50,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "hypernet_hidden_size": 64,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_drop_prob": 0.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "max_seq_length": 128,
  "mixing": "bert-bottleneck",
  "model_type": "bert",
  "normalization_type": "layer_norm",
  "num_attention_heads": 12,
  "num_feedforward_networks": 1,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "random_layer_selection_probability": 0.1,
  "rewire": 0,
  "sample_hidden_size": [
    360,
    240,
    240,
    360,
    360,
    360,
    540,
    360,
    480,
    540,
    540,
    600
  ],
  "sample_intermediate_size": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  "sample_num_attention_heads": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  "sample_num_hidden_layers": 12,
  "search_space_id": null,
  "torch_dtype": "float32",
  "transformers_version": "4.11.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "use_hypernet_w_low_rank": 0,
  "vocab_size": 30522
}
loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /data/home/ganayu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}
loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /data/home/ganayu/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /data/home/ganayu/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /data/home/ganayu/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /data/home/ganayu/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}
loading weights file /fsx/ganayu/experiments/supershaper/aug13_v1_acadbertdata_supernet_retrain_subnet_125Ksteps/supernet_continue/best_model/pytorch_model.bin
Some weights of the model checkpoint at /fsx/ganayu/experiments/supershaper/aug13_v1_acadbertdata_supernet_retrain_subnet_125Ksteps/supernet_continue/best_model were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /fsx/ganayu/experiments/supershaper/aug13_v1_acadbertdata_supernet_retrain_subnet_125Ksteps/supernet_continue/best_model and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
loading configuration file /fsx/ganayu/experiments/supershaper/aug13_v1_acadbertdata_supernet_retrain_subnet_125Ksteps/supernet_continue/best_model/config.json
Model config BertConfig {
  "_name_or_path": "/fsx/ganayu/experiments/supershaper/aug9_acadbertdata_supernet_v1/acav1/best_model",
  "additional_random_softmaxing": false,
  "alpha_divergence": 0,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bottleneck_rank": 50,
  "classifier_dropout": null,
  "finetuning_task": "cola",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0,
  "hidden_size": 768,
  "hypernet_hidden_size": 64,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_drop_prob": 0.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "max_seq_length": 128,
  "mixing": "bert-bottleneck",
  "model_type": "bert",
  "normalization_type": "layer_norm",
  "num_attention_heads": 12,
  "num_feedforward_networks": 1,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "random_layer_selection_probability": 0.1,
  "rewire": 0,
  "sample_hidden_size": [
    360,
    240,
    240,
    360,
    360,
    360,
    540,
    360,
    480,
    540,
    540,
    600
  ],
  "sample_intermediate_size": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  "sample_num_attention_heads": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  "sample_num_hidden_layers": 12,
  "search_space_id": null,
  "torch_dtype": "float32",
  "transformers_version": "4.11.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "use_hypernet_w_low_rank": 0,
  "vocab_size": 30522
}
loading configuration file /fsx/ganayu/experiments/supershaper/aug18_finetune_acabertdata_bertbasestandalone_mnli_ckptneeded/23_bertbase_cola_5e-5_32_4/config.json
Model config BertConfig {
  "_name_or_path": "/fsx/ganayu/experiments/supershaper/aug9_bert_roberta_standalone_noinit_nobottle_acabertpreproc/bertbase/best_model",
  "additional_random_softmaxing": false,
  "alpha_divergence": 0,
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bottleneck_rank": 50,
  "classifier_dropout": null,
  "finetuning_task": "cola",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "hypernet_hidden_size": 64,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_drop_prob": 0.0,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "max_seq_length": 128,
  "mixing": "attention",
  "model_type": "bert",
  "normalization_type": "layer_norm",
  "num_attention_heads": 12,
  "num_feedforward_networks": 1,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "problem_type": "single_label_classification",
  "random_layer_selection_probability": 0.1,
  "rewire": 0,
  "sample_hidden_size": 768,
  "sample_intermediate_size": [
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072,
    3072
  ],
  "sample_num_attention_heads": [
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12,
    12
  ],
  "sample_num_hidden_layers": 12,
  "search_space_id": null,
  "torch_dtype": "float32",
  "transformers_version": "4.11.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "use_hypernet_w_low_rank": 0,
  "vocab_size": 30522
}
loading weights file /fsx/ganayu/experiments/supershaper/aug18_finetune_acabertdata_bertbasestandalone_mnli_ckptneeded/23_bertbase_cola_5e-5_32_4/pytorch_model.bin
All model checkpoint weights were used when initializing BertForSequenceClassification.
All the weights of BertForSequenceClassification were initialized from the model checkpoint at /fsx/ganayu/experiments/supershaper/aug18_finetune_acabertdata_bertbasestandalone_mnli_ckptneeded/23_bertbase_cola_5e-5_32_4.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.
08/19/2022 20:40:21 - WARNING - datasets.fingerprint -   Parameter 'function'=<function main.<locals>.preprocess_function at 0x7ffaf2a633a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
08/19/2022 20:40:21 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /data/home/ganayu/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-59ce8cfd8e09b24c.arrow
08/19/2022 20:40:21 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /data/home/ganayu/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-373bf2215a6709ea.arrow
08/19/2022 20:40:21 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /data/home/ganayu/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-6786bf68fba9f210.arrow
08/19/2022 20:40:21 - INFO - __main__ -   Sample 1344 of the training set: {'input_ids': [101, 1996, 15653, 11227, 2029, 14673, 2003, 2175, 15343, 2091, 5514, 2084, 1045, 2064, 2128, 20192, 2102, 2068, 2024, 5186, 11937, 21756, 1010, 2065, 1045, 2079, 2360, 2061, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}.
08/19/2022 20:40:21 - INFO - __main__ -   Sample 4624 of the training set: {'input_ids': [101, 2027, 2903, 2009, 2000, 2022, 3733, 2000, 5754, 6977, 3841, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}.
08/19/2022 20:40:21 - INFO - __main__ -   Sample 5589 of the training set: {'input_ids': [101, 8788, 8682, 2039, 2009, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'labels': 1}.
08/19/2022 20:40:30 - INFO - __main__ -   ***** Running training *****
08/19/2022 20:40:30 - INFO - __main__ -     Num examples = 8551
08/19/2022 20:40:30 - INFO - __main__ -     Num Epochs = 4
08/19/2022 20:40:30 - INFO - __main__ -     Instantaneous batch size per device = 16
08/19/2022 20:40:30 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32
08/19/2022 20:40:30 - INFO - __main__ -     Gradient Accumulation steps = 1
08/19/2022 20:40:30 - INFO - __main__ -     Total optimization steps = 1072
  0%|                                                                                                                | 0/1072 [00:02<?, ?it/s]